{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNMeans allows clustering related data. We can tell it how many groups we want it to use, and it will group based on that.\n",
    "In this case, we will use wikipedia articles and we will perform a naive word extraction.\n",
    "To be able to work with documents, we will use [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = []\n",
    "articles = [\n",
    "    'https://en.wikipedia.org/wiki/Tf%E2%80%93idf',\n",
    "    'https://en.wikipedia.org/wiki/Nintendo',\n",
    "    'https://en.wikipedia.org/wiki/Video_game',\n",
    "    'https://en.wikipedia.org/wiki/War',\n",
    "    'https://en.wikipedia.org/wiki/Love',\n",
    "    'https://en.wikipedia.org/wiki/Stephen_Hawking',\n",
    "    'https://en.wikipedia.org/wiki/Metal_Gear_Solid',\n",
    "    'https://en.wikipedia.org/wiki/Neil_deGrasse_Tyson',\n",
    "    'https://en.wikipedia.org/wiki/The_Cure',\n",
    "    'https://en.wikipedia.org/wiki/Metallica',\n",
    "    'https://en.wikipedia.org/wiki/Freddie_Mercury',\n",
    "    'https://en.wikipedia.org/wiki/Hatred,',\n",
    "    'https://en.wikipedia.org/wiki/Peace',\n",
    "]\n",
    "article_titles = [\n",
    "    'tf-idf',\n",
    "    'Nintendo',\n",
    "    'VideoGames',\n",
    "    'War',\n",
    "    'Love',\n",
    "    'Stephen Hawking',\n",
    "    'Metal Gear Solid',\n",
    "    'Neil deGrasse Tyson',\n",
    "    'The cure',\n",
    "    'Metallica',\n",
    "    'Freddy Mercury',\n",
    "    'Hatred',\n",
    "    'Peace',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in articles:\n",
    "    response = requests.get(article)\n",
    "    soup = BeautifulSoup(response.content)\n",
    "    paragraphs = soup.find_all('p')\n",
    "    extracted_text = [paragraph.get_text().strip('\\n') for paragraph in paragraphs]\n",
    "    extracted_text = ' '.join(extracted_text)\n",
    "    documents.append(re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", extracted_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "sparse_mat = tfidf.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the tf-idf matrix, we can proceed.\n",
    "We will start by extracting the [PCA](https://en.wikipedia.org/wiki/Principal_component_analysis) on the data. With this we will be able to reduce the dimensions of our data, extracting the principal components of the dataset.\n",
    "After that we will use KMeans to create our clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristian/.envs/jupyter/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/cristian/.envs/jupyter/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import pandas as pd\n",
    "\n",
    "pca = TruncatedSVD(n_components=30)\n",
    "normalizer = Normalizer(copy=False)\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "pipeline = make_pipeline(pca, normalizer, kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label                title\n",
      "    0             Nintendo\n",
      "    0           VideoGames\n",
      "    0     Metal Gear Solid\n",
      "    1               Hatred\n",
      "    2                  War\n",
      "    2                 Love\n",
      "    2                Peace\n",
      "    3             The cure\n",
      "    3            Metallica\n",
      "    4               tf-idf\n",
      "    5      Stephen Hawking\n",
      "    5  Neil deGrasse Tyson\n",
      "    5       Freddy Mercury\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(sparse_mat)\n",
    "labels = pipeline.predict(sparse_mat)\n",
    "df = pd.DataFrame({'label': labels, 'title': article_titles})\n",
    "print(df.sort_values('label').to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you examine the output, you can see that articles that have similar topics are in the same cluster. You can add some more articles and play around with n_components(TruncatedSVD) and n_clusters(KMeans) to see how the behavior varies with that.\n",
    "As a bonus, we can also compute the simmilarity among the documents using NMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freddy Mercury         1.000000\n",
      "Metallica              0.998102\n",
      "The cure               0.997756\n",
      "Stephen Hawking        0.971825\n",
      "Neil deGrasse Tyson    0.943056\n",
      "Metal Gear Solid       0.336674\n",
      "War                    0.060511\n",
      "Peace                  0.060456\n",
      "Love                   0.060440\n",
      "VideoGames             0.017816\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf_pipeline = make_pipeline(NMF(n_components=5), Normalizer())\n",
    "norm_nmf = nmf_pipeline.fit_transform(sparse_mat)\n",
    "nmf_df = pd.DataFrame(norm_nmf, index=article_titles)\n",
    "test_topic = nmf_df.loc['Freddy Mercury']\n",
    "similarities = nmf_df.dot(test_topic)\n",
    "print(similarities.nlargest(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in this case, we were able to extract more information. The recommendations for 'Freddy Mercury' are first in the topic 'music', jumping to the topic 'person' or 'biography'. Also it is easy to notice the big jump between the related topics and unrelated ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
